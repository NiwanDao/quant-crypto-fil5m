import pandas as pd
import numpy as np
from ta.momentum import RSIIndicator, StochasticOscillator, ROCIndicator
from ta.trend import EMAIndicator, MACD, ADXIndicator, IchimokuIndicator
from ta.volatility import BollingerBands, AverageTrueRange, DonchianChannel
from ta.volume import OnBalanceVolumeIndicator, AccDistIndexIndicator
from ta.others import DailyReturnIndicator


def build_features_safe(df: pd.DataFrame) -> pd.DataFrame:
    """
    å®‰å…¨ç‰ˆæœ¬çš„ç‰¹å¾å·¥ç¨‹ - é¿å…æ•°æ®æ³„éœ²
    """
    df = df.copy()
    
    # ç¡®ä¿æŒ‰æ—¶é—´é¡ºåºå¤„ç†
    df = df.sort_index()
    
    # 1. åŸºç¡€ä»·æ ¼ç‰¹å¾ - åªä½¿ç”¨åŽ†å²ä¿¡æ¯
    df['returns'] = df['close'].pct_change()
    df['returns_lag1'] = df['returns'].shift(1)  # ä½¿ç”¨æ»žåŽå€¼
    df['high_low_ratio'] = df['high'] / df['low']
    df['open_close_ratio'] = df['close'] / df['open']
    df['body_size'] = abs(df['close'] - df['open']) / df['open']
    
    # 2. è¶‹åŠ¿ç‰¹å¾ - ä½¿ç”¨æ»žåŽå€¼é¿å…æœªæ¥ä¿¡æ¯
    for period in [5, 10, 20]:
        # ä½¿ç”¨shift(1)ç¡®ä¿åªä½¿ç”¨åŽ†å²æ•°æ®è®¡ç®—EMA
        df[f'ema_{period}'] = df['close'].shift(1).ewm(span=period).mean()
        df[f'price_ema_ratio_{period}'] = df['close'] / df[f'ema_{period}']
    
    # 3. MACD - ä½¿ç”¨åŽ†å²æ•°æ®è®¡ç®—
    def safe_macd(close_series, fast=12, slow=26, signal=9):
        """å®‰å…¨çš„MACDè®¡ç®—"""
        ema_fast = close_series.shift(1).ewm(span=fast).mean()
        ema_slow = close_series.shift(1).ewm(span=slow).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal).mean()
        histogram = macd_line - signal_line
        return macd_line, signal_line, histogram
    
    macd_line, signal_line, histogram = safe_macd(df['close'])
    df['macd'] = macd_line
    df['macd_signal'] = signal_line
    df['macd_histogram'] = histogram
    
    # 4. RSI - ä½¿ç”¨åŽ†å²æ•°æ®è®¡ç®—
    def safe_rsi(series, window=14):
        """å®‰å…¨çš„RSIè®¡ç®—"""
        # ä½¿ç”¨shiftç¡®ä¿æ²¡æœ‰æœªæ¥ä¿¡æ¯
        deltas = series.shift(1).diff()
        gains = deltas.where(deltas > 0, 0)
        losses = -deltas.where(deltas < 0, 0)
        
        avg_gains = gains.rolling(window=window, min_periods=1).mean()
        avg_losses = losses.rolling(window=window, min_periods=1).mean()
        
        rs = avg_gains / (avg_losses + 1e-10)
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    for period in [7, 14]:
        df[f'rsi_{period}_safe'] = safe_rsi(df['close'], period)
    
    # 5. å¸ƒæž—å¸¦ - ä½¿ç”¨åŽ†å²æ•°æ®
    def safe_bollinger_bands(close_series, window=20, num_std=2):
        """å®‰å…¨çš„å¸ƒæž—å¸¦è®¡ç®—"""
        rolling_mean = close_series.shift(1).rolling(window=window).mean()
        rolling_std = close_series.shift(1).rolling(window=window).std()
        
        upper_band = rolling_mean + (rolling_std * num_std)
        lower_band = rolling_mean - (rolling_std * num_std)
        
        return upper_band, lower_band, rolling_mean
    
    bb_upper, bb_lower, bb_middle = safe_bollinger_bands(df['close'])
    df['bb_upper_safe'] = bb_upper
    df['bb_lower_safe'] = bb_lower
    df['bb_middle_safe'] = bb_middle
    df['bb_position_safe'] = (df['close'] - bb_lower) / (bb_upper - bb_lower)
    
    # 6. æˆäº¤é‡ç‰¹å¾ - ä½¿ç”¨æ»žåŽå€¼
    df['volume_lag1'] = df['volume'].shift(1)
    df['volume_ratio_safe'] = df['volume_lag1'] / df['volume_lag1'].rolling(20).mean()
    
    # 7. ä»·æ ¼ä½ç½®ç‰¹å¾ - ä½¿ç”¨åŽ†å²é«˜ä½Žç‚¹
    df['resistance_20'] = df['high'].shift(1).rolling(20).max()  # ä½¿ç”¨shift(1)
    df['support_20'] = df['low'].shift(1).rolling(20).min()     # ä½¿ç”¨shift(1)
    df['breakout_high'] = (df['close'] > df['resistance_20']).astype(int)
    df['breakout_low'] = (df['close'] < df['support_20']).astype(int)
    
    # æ¸…ç†æ•°æ®
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df = df.dropna()
    
    print(f"âœ… å®‰å…¨ç‰¹å¾æž„å»ºå®Œæˆ: {len(df.columns)} ä¸ªç‰¹å¾")
    print(f"ðŸ“Š æœ‰æ•ˆæ ·æœ¬æ•°: {len(df)}")
    
    return df


def detect_data_leakage(df, target_col='y'):
    """æ£€æµ‹æ•°æ®æ³„éœ²"""
    print("ðŸ” æ£€æµ‹æ•°æ®æ³„éœ²...")
    
    # æ£€æŸ¥ç‰¹å¾ä¸Žæ ‡ç­¾çš„ç›¸å…³æ€§
    feature_cols = [col for col in df.columns if col != target_col]
    correlations = []
    
    for col in feature_cols:
        corr = df[col].corr(df[target_col])
        correlations.append((col, corr))
    
    # æŽ’åºå¹¶æ˜¾ç¤ºé«˜ç›¸å…³æ€§ç‰¹å¾
    correlations.sort(key=lambda x: abs(x[1]), reverse=True)
    
    print("ðŸ“Š ç‰¹å¾ä¸Žæ ‡ç­¾ç›¸å…³æ€§Top 10:")
    suspicious_features = []
    for col, corr in correlations[:10]:
        print(f"  {col}: {corr:.4f}")
        if abs(corr) > 0.8:
            suspicious_features.append((col, corr))
    
    if suspicious_features:
        print("âŒ å‘çŽ°å¯ç–‘çš„é«˜ç›¸å…³æ€§ç‰¹å¾ï¼ˆå¯èƒ½æ•°æ®æ³„éœ²ï¼‰:")
        for col, corr in suspicious_features:
            print(f"  âš ï¸ {col}: {corr:.4f}")
        return False
    else:
        print("âœ… æœªå‘çŽ°æ˜Žæ˜¾æ•°æ®æ³„éœ²")
        return True

def build_labels_safe(df: pd.DataFrame, forward_n: int = 4, thr: float = 0.008) -> pd.DataFrame:
    """
    ä¿®å¤ç‰ˆæ ‡ç­¾ç”Ÿæˆ - åˆ›å»ºæ›´åˆç†çš„äº¤æ˜“ä¿¡å·
    """
    df = df.copy()
    
    # æ–¹æ³•1: ç®€å•æ”¶ç›ŠçŽ‡æ ‡ç­¾ (ä¿æŒå…¼å®¹æ€§)
    future_return = df['close'].pct_change(forward_n).shift(-forward_n)
    df['y_simple'] = (future_return > thr).astype(int)
    
    # æ–¹æ³•2: æ”¹è¿›çš„æ³¢åŠ¨çŽ‡è°ƒæ•´æ ‡ç­¾
    volatility = df['returns'].rolling(forward_n).std()
    adaptive_threshold = thr * (volatility / volatility.median())  # æ ¹æ®æ³¢åŠ¨çŽ‡è°ƒæ•´é˜ˆå€¼
    df['y_vol_adjusted'] = (future_return > adaptive_threshold).astype(int)
    
    # æ–¹æ³•3: ç›¸å¯¹å¼ºåº¦æ ‡ç­¾ (æŽ¨è)
    future_max = df['close'].shift(-forward_n).rolling(forward_n).max()
    future_min = df['close'].shift(-forward_n).rolling(forward_n).min()
    
    # ä¹°å…¥ä¿¡å·: æœªæ¥æœ€é«˜ä»·æ¯”å½“å‰ä»·ä¸Šæ¶¨è¶…è¿‡é˜ˆå€¼
    buy_signal = (future_max / df['close'] - 1) > thr
    
    # å–å‡ºä¿¡å·: æœªæ¥æœ€ä½Žä»·æ¯”å½“å‰ä»·ä¸‹è·Œè¶…è¿‡é˜ˆå€¼  
    sell_signal = (1 - future_min / df['close']) > thr
    
    # ä¸‰åˆ†ç±»æ ‡ç­¾
    df['y_tri'] = 0  # 0: æŒæœ‰
    df.loc[buy_signal & ~sell_signal, 'y_tri'] = 1  # 1: ä¹°å…¥
    df.loc[sell_signal & ~buy_signal, 'y_tri'] = 2  # 2: å–å‡º
    
    # ä½¿ç”¨ä¸‰åˆ†ç±»ä¸­çš„ä¹°å…¥ä¿¡å·ä½œä¸ºä¸»è¦æ ‡ç­¾
    df['y'] = (df['y_tri'] == 1).astype(int)
    
    # åˆ é™¤æœªæ¥æ•°æ®ä¸å¯ç”¨çš„è¡Œ
    df = df.dropna()
    
    # åˆ†æžæ ‡ç­¾åˆ†å¸ƒ
    print("ðŸŽ¯ æ ‡ç­¾åˆ†å¸ƒåˆ†æž:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"  ä¹°å…¥ä¿¡å· (y=1): {(df['y'] == 1).sum()} ({(df['y'] == 1).mean():.2%})")
    print(f"  éžä¹°å…¥ä¿¡å· (y=0): {(df['y'] == 0).sum()} ({(df['y'] == 0).mean():.2%})")
    
    if (df['y'] == 1).mean() > 0.7 or (df['y'] == 1).mean() < 0.3:
        print("âš ï¸  è­¦å‘Š: æ ‡ç­¾ä¸¥é‡ä¸å¹³è¡¡ï¼Œå»ºè®®è°ƒæ•´é˜ˆå€¼!")
        print(f"ðŸ’¡ å»ºè®®é˜ˆå€¼èŒƒå›´: {thr * 0.5:.4f} - {thr * 2:.4f}")
    
    return df

# ç‰¹å¾é€‰æ‹©å‡½æ•° - åˆ é™¤ä½Žè´¨é‡ç‰¹å¾
def select_important_features(df, target_col='y', top_k=30):
    """
    é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾
    """
    from sklearn.ensemble import RandomForestClassifier
    
    X = df.drop(columns=[target_col, 'y_tri', 'y_simple', 'y_vol_adjusted'], errors='ignore')
    y = df[target_col]
    
    # ä½¿ç”¨éšæœºæ£®æž—è¿›è¡Œç‰¹å¾é‡è¦æ€§æŽ’åº
    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    rf.fit(X.fillna(0), y)
    
    # èŽ·å–ç‰¹å¾é‡è¦æ€§
    importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': rf.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # é€‰æ‹©top_kç‰¹å¾
    selected_features = importance_df.head(top_k)['feature'].tolist()
    
    print(f"ðŸŽ¯ é€‰æ‹©äº† {len(selected_features)} ä¸ªæœ€é‡è¦ç‰¹å¾")
    print("ðŸ† Top 10 ç‰¹å¾:")
    for i, row in importance_df.head(10).iterrows():
        print(f"  {i+1:2d}. {row['feature']}: {row['importance']:.4f}")
    
    return df[selected_features + [target_col]]

# ä½¿ç”¨å»ºè®®
# # 1. ç”Ÿæˆç‰¹å¾
# df_with_features = build_features(raw_data)

# # 2. ç”Ÿæˆæ ‡ç­¾  
# df_with_labels = build_labels(df_with_features, forward_n=4, thr=0.01)  # å°è¯•1%é˜ˆå€¼

# # 3. ç‰¹å¾é€‰æ‹©
# final_df = select_important_features(df_with_labels, top_k=25)

# print(f"ðŸŽ‰ æœ€ç»ˆæ•°æ®é›†: {final_df.shape}")
# print(f"ðŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {final_df['y'].value_counts(normalize=True).to_dict()}")    