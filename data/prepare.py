import os
import time
import ccxt
import pandas as pd
import yaml
from datetime import datetime, timezone
import argparse
import sys

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥utils
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from utils.features import build_features_safe, build_multi_feature_labels, detect_data_leakage

CONF_PATH = "conf/config.yml"


def load_conf():
    with open(CONF_PATH, "r") as f:
        return yaml.safe_load(f)


def fetch_ohlcv_all(ex, symbol, timeframe, since_ms, until_ms, batch_limit=1000):
    """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„OHLCVæ•°æ®ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
    all_rows = []
    since = since_ms

    print(f"ğŸ“¡ å¼€å§‹è·å–æ•°æ®: {symbol} {timeframe}")
    print(
        f"â° æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(since_ms/1000)} åˆ° {datetime.fromtimestamp(until_ms/1000)}"
    )

    batch_count = 0
    max_batches = 50  # é˜²æ­¢æ— é™å¾ªç¯
    consecutive_errors = 0
    max_consecutive_errors = 3

    while since < until_ms and batch_count < max_batches:
        batch_count += 1

        try:
            print(
                f"ğŸ”„ è·å–æ‰¹æ¬¡ {batch_count}, æ—¶é—´æˆ³: {since} ({datetime.fromtimestamp(since/1000)})"
            )

            # ä½¿ç”¨fetch_ohlcvè·å–æ•°æ®
            ohlcv_data = ex.fetch_ohlcv(
                symbol, timeframe=timeframe, since=since, limit=batch_limit
            )

            if not ohlcv_data:
                print("âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œå¯èƒ½å·²åˆ°è¾¾æ•°æ®æœ«å°¾")
                break

            # éªŒè¯æ•°æ®è´¨é‡
            if not validate_ohlcv_data(ohlcv_data):
                print("âŒ æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥")
                consecutive_errors += 1
                if consecutive_errors >= max_consecutive_errors:
                    print("âŒ è¿ç»­é”™è¯¯è¿‡å¤šï¼Œåœæ­¢è·å–")
                    break
                continue

            consecutive_errors = 0  # é‡ç½®é”™è¯¯è®¡æ•°
            print(f"ğŸ“Š è·å–åˆ° {len(ohlcv_data)} æ¡Kçº¿æ•°æ®")

            # æ·»åŠ åˆ°æ€»æ•°æ®
            all_rows.extend(ohlcv_data)

            # æ›´æ–°ä¸‹ä¸€ä¸ªèµ·å§‹æ—¶é—´ï¼ˆä½¿ç”¨æœ€åä¸€æ ¹Kçº¿çš„æ—¶é—´æˆ³ + 1ä¸ªæ—¶é—´é—´éš”ï¼‰
            last_timestamp = ohlcv_data[-1][0]

            # è®¡ç®—æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰
            timeframe_ms = {
                "15m": 15 * 60 * 1000,
                "1h": 60 * 60 * 1000,
                "4h": 4 * 60 * 60 * 1000,
                "1d": 24 * 60 * 60 * 1000,
            }.get(
                timeframe, 15 * 60 * 1000
            )  # é»˜è®¤15åˆ†é’Ÿ

            since = last_timestamp + timeframe_ms

            # å¦‚æœæœ€åä¸€æ ¹Kçº¿çš„æ—¶é—´å·²ç»è¶…è¿‡ç»“æŸæ—¶é—´ï¼Œå°±åœæ­¢
            if last_timestamp >= until_ms:
                print("âœ… å·²è¾¾åˆ°ç»“æŸæ—¶é—´ï¼Œåœæ­¢è·å–")
                break

            # é€Ÿç‡é™åˆ¶
            time.sleep(ex.rateLimit / 1000.0 if hasattr(ex, "rateLimit") else 0.5)

        except Exception as e:
            print(f"âŒ è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
            consecutive_errors += 1
            if consecutive_errors >= max_consecutive_errors:
                print("âŒ è¿ç»­é”™è¯¯è¿‡å¤šï¼Œåœæ­¢è·å–")
                break
            time.sleep(2)  # é”™è¯¯åç­‰å¾…æ›´é•¿æ—¶é—´

    print(f"âœ… æ•°æ®è·å–å®Œæˆï¼Œæ€»å…± {len(all_rows)} æ¡è®°å½•")
    return all_rows


def validate_ohlcv_data(ohlcv_data):
    """éªŒè¯OHLCVæ•°æ®è´¨é‡"""
    if not ohlcv_data or len(ohlcv_data) == 0:
        return False

    for row in ohlcv_data:
        if len(row) != 6:
            print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯: æœŸæœ›6åˆ—ï¼Œå®é™…{len(row)}åˆ—")
            return False

        timestamp, open_price, high, low, close, volume = row

        # æ£€æŸ¥æ—¶é—´æˆ³
        if timestamp <= 0:
            print(f"âŒ æ— æ•ˆæ—¶é—´æˆ³: {timestamp}")
            return False

        # æ£€æŸ¥ä»·æ ¼æ•°æ®
        if not all(
            isinstance(x, (int, float)) and x > 0
            for x in [open_price, high, low, close]
        ):
            print(f"âŒ æ— æ•ˆä»·æ ¼æ•°æ®: O:{open_price} H:{high} L:{low} C:{close}")
            return False

        # æ£€æŸ¥OHLCé€»è¾‘
        if not (low <= open_price <= high and low <= close <= high):
            print(f"âŒ OHLCé€»è¾‘é”™è¯¯: O:{open_price} H:{high} L:{low} C:{close}")
            return False

        # æ£€æŸ¥æˆäº¤é‡
        if not isinstance(volume, (int, float)) or volume < 0:
            print(f"âŒ æ— æ•ˆæˆäº¤é‡: {volume}")
            return False

    return True


def validate_final_data(df):
    """éªŒè¯æœ€ç»ˆæ•°æ®çš„è´¨é‡"""
    print("ğŸ” æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")

    # æ£€æŸ¥åŸºæœ¬æ•°æ®
    if df.empty:
        print("âŒ æ•°æ®ä¸ºç©º")
        return False

    # æ£€æŸ¥å¿…è¦åˆ—
    required_columns = ["open", "high", "low", "close", "volume"]
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        print(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
        return False

    # æ£€æŸ¥æ•°æ®èŒƒå›´
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   - æ€»è®°å½•æ•°: {len(df)}")
    print(f"   - æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
    print(f"   - ä»·æ ¼èŒƒå›´: {df['low'].min():.2f} - {df['high'].max():.2f}")

    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_data = df[required_columns].isnull().sum()
    if missing_data.any():
        print(f"âŒ å‘ç°ç¼ºå¤±å€¼: {missing_data[missing_data > 0].to_dict()}")
        return False

    # æ£€æŸ¥ä»·æ ¼é€»è¾‘
    invalid_ohlc = df[
        (df["low"] > df["high"])
        | (df["open"] < df["low"])
        | (df["open"] > df["high"])
        | (df["close"] < df["low"])
        | (df["close"] > df["high"])
    ]

    if not invalid_ohlc.empty:
        print(f"âŒ å‘ç° {len(invalid_ohlc)} æ¡OHLCé€»è¾‘é”™è¯¯çš„æ•°æ®")
        return False

    # æ£€æŸ¥è´Ÿå€¼
    negative_values = df[(df[required_columns] <= 0).any(axis=1)]
    if not negative_values.empty:
        print(f"âŒ å‘ç° {len(negative_values)} æ¡åŒ…å«è´Ÿå€¼æˆ–é›¶çš„æ•°æ®")
        return False

    print("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
    return True


def debug_exchange_info(ex, symbol):
    """è°ƒè¯•äº¤æ˜“æ‰€å’Œä¿¡æ¯"""
    print(f"ğŸ” äº¤æ˜“æ‰€: {ex.id}")
    print(f"ğŸ” äº¤æ˜“å¯¹: {symbol}")

    try:
        # æ£€æŸ¥å¸‚åœºä¿¡æ¯
        markets = ex.load_markets()
        if symbol in markets:
            print(f"âœ… äº¤æ˜“å¯¹ {symbol} å­˜åœ¨")
        else:
            print(f"âŒ äº¤æ˜“å¯¹ {symbol} ä¸å­˜åœ¨")
            print(f"å¯ç”¨äº¤æ˜“å¯¹ç¤ºä¾‹: {list(markets.keys())[:5]}")

        # æ£€æŸ¥æœåŠ¡å™¨æ—¶é—´
        server_time = ex.fetch_time()
        print(f"ğŸ•’ æœåŠ¡å™¨æ—¶é—´: {datetime.fromtimestamp(server_time/1000)}")

    except Exception as e:
        print(f"âŒ äº¤æ˜“æ‰€ä¿¡æ¯æ£€æŸ¥å¤±è´¥: {e}")


def test_fetch_recent_data(ex, symbol, timeframe):
    """æµ‹è¯•è·å–æœ€è¿‘çš„æ•°æ®"""
    print("ğŸ§ª æµ‹è¯•è·å–æœ€è¿‘æ•°æ®...")
    try:
        # è·å–æœ€è¿‘çš„æ•°æ®
        recent_data = ex.fetch_ohlcv(symbol, timeframe=timeframe, limit=5)
        if recent_data:
            print(f"âœ… æµ‹è¯•æˆåŠŸï¼è·å–åˆ° {len(recent_data)} æ¡æœ€è¿‘æ•°æ®")
            for i, row in enumerate(recent_data[-3:]):  # æ˜¾ç¤ºæœ€å3æ¡
                dt = datetime.fromtimestamp(row[0] / 1000)
                print(
                    f"   {i+1}. {dt}: O:{row[1]:.2f} H:{row[2]:.2f} L:{row[3]:.2f} C:{row[4]:.2f} V:{row[5]:.2f}"
                )
            return True
        else:
            print("âŒ æµ‹è¯•å¤±è´¥ï¼šæ²¡æœ‰è·å–åˆ°æ•°æ®")
            return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def parse_date_arg(date_str, is_end=False):
    """è§£ææ—¥æœŸå‚æ•°ï¼Œæ”¯æŒ 'YYYY-MM-DD'ã€'YYYY-M-D' å’Œ 'now'ï¼ˆä»…é™ç»“æŸæ—¶é—´ï¼‰"""
    if date_str.lower() == "now":
        if not is_end:
            raise ValueError("'now' ä»…å¯ç”¨äº --to")
        return datetime.now(timezone.utc)

    # ä½¿ç”¨ pandas è§£æå¹¶è®¾ä¸º UTC èµ·å§‹/ç»“æŸ
    dt = pd.to_datetime(date_str, utc=True)
    dt = dt.to_pydatetime()
    if is_end:
        # è®¾ä¸ºå½“å¤© 23:59:59ï¼ˆä¸åŸè„šæœ¬ä¸€è‡´ï¼‰
        return dt.replace(
            hour=23, minute=59, second=59, microsecond=0, tzinfo=timezone.utc
        )
    return dt.replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc)


def default_output_path(start_dt: datetime, end_dt: datetime | None):
    def ym(dt: datetime):
        return f"{dt.year}_{dt.month}"

    start_part = ym(start_dt)
    end_part = "now" if end_dt is None else ym(end_dt)
    return os.path.join("data", f"feat_{start_part}_to_{end_part}.parquet")


def ensure_parent_dir(path: str):
    parent = os.path.dirname(path)
    if parent and not os.path.exists(parent):
        os.makedirs(parent, exist_ok=True)


def process_range(
    ex,
    conf,
    start_dt: datetime,
    end_dt: datetime | None,
    output_file: str | None = None,
):
    since_ms = int(start_dt.timestamp() * 1000)
    until_ms = int((end_dt or datetime.now(timezone.utc)).timestamp() * 1000)

    symbol = conf["symbol"]
    timeframe = conf["timeframe"]
    batch_limit = conf["fetch"].get("batch_limit", 500)

    print(f"\nğŸ¯ å¼€å§‹è·å–å†å²æ•°æ®: {symbol} {timeframe}")
    print(
        f"ğŸ“… æ—¶é—´èŒƒå›´: {start_dt.date()} åˆ° {(end_dt.date() if end_dt else datetime.now(timezone.utc).date())}"
    )
    print(f"â° æ—¶é—´æˆ³: {since_ms} åˆ° {until_ms}")

    rows = fetch_ohlcv_all(
        ex, symbol, timeframe, since_ms, until_ms, batch_limit=batch_limit
    )

    if not rows:
        print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
        return

    # å¤„ç†æ•°æ®
    df = pd.DataFrame(rows, columns=["ts", "open", "high", "low", "close", "volume"])
    df["ts"] = pd.to_datetime(df["ts"], unit="ms", utc=True)
    df.set_index("ts", inplace=True)
    df.sort_index(inplace=True)

    print(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"   - æ€»è®°å½•æ•°: {len(df)}")
    print(f"   - æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
    print(f"   - ä»·æ ¼èŒƒå›´: {df['low'].min():.2f} - {df['high'].max():.2f}")
    print(f"   - æœ€æ–°æ”¶ç›˜ä»·: {df['close'].iloc[-1]:.2f}")

    # æ„å»ºç‰¹å¾å’Œæ ‡ç­¾
    print("\nğŸ”§ æ„å»ºç‰¹å¾å’Œæ ‡ç­¾...")
    df = build_features_safe(df)

    df = build_multi_feature_labels(
        df,
        forward_n=conf["features"]["forward_n"],
        base_thr=conf["features"]["label_threshold"],
    )

    # æ•°æ®æ³„éœ²æ£€æµ‹
    if not detect_data_leakage(df):
        print("âŒ æ•°æ®æ³„éœ²æ£€æµ‹å¤±è´¥ï¼Œåœæ­¢å¤„ç†")
        return None

    # æœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥
    print("\nğŸ” è¿›è¡Œæœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥...")
    if not validate_final_data(df):
        print("âŒ æœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥")
        return

    # ä¿å­˜æ•°æ®
    final_output = output_file or default_output_path(start_dt, end_dt)
    ensure_parent_dir(final_output)
    df.to_parquet(final_output)

    print(f"\nâœ… æ•°æ®ä¿å­˜æˆåŠŸ: {final_output}")
    print(f"ğŸ“Š æœ€ç»ˆæ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")


def main():
    parser = argparse.ArgumentParser(description="æŒ‰æ—¶é—´èŒƒå›´ç”Ÿæˆç‰¹å¾æ•°æ®é›†")
    parser.add_argument(
        "--from", dest="start_date", required=False, help="å¼€å§‹æ—¥æœŸï¼Œå¦‚ 2024-08-01"
    )
    parser.add_argument(
        "--to", dest="end_date", required=False, help="ç»“æŸæ—¥æœŸï¼Œå¦‚ 2025-03-31 æˆ– now"
    )
    parser.add_argument(
        "--out", dest="output_path", default=None, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆ.parquetï¼‰"
    )
    parser.add_argument(
        "--run-all",
        action="store_true",
        help="ä¸€æ¬¡æ€§ç”Ÿæˆä¸‰ä¸ªæ•°æ®é›†ï¼š2024-08~2025-03ã€2025-03~2025-06ã€2025-06~now",
    )
    args = parser.parse_args()

    conf = load_conf()

    # åˆ›å»ºäº¤æ˜“æ‰€å®ä¾‹
    exchange_config = {
        "enableRateLimit": conf["exchange"].get("enableRateLimit", True),
        "options": conf["exchange"].get("options", {}),
    }

    # æ·»åŠ ä»£ç†é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if "proxy" in conf["exchange"]:
        exchange_config["proxies"] = conf["exchange"]["proxy"]

    ex = ccxt.__dict__[conf["exchange"]["id"]](exchange_config)

    symbol = conf["symbol"]
    timeframe = conf["timeframe"]
    batch_limit = conf["fetch"].get("batch_limit", 500)

    # è°ƒè¯•ä¿¡æ¯
    debug_exchange_info(ex, symbol)

    # æµ‹è¯•è·å–æ•°æ®
    if not test_fetch_recent_data(ex, symbol, timeframe):
        print("âŒ æ— æ³•è·å–æ•°æ®ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
        return

    # --run-all æ¨¡å¼ï¼šä¸€æ¬¡æ€§è·‘å®Œä¸‰æ®µæ•°æ®
    if args.run_all:
        ranges = [
            (
                datetime(2024, 8, 1, tzinfo=timezone.utc),
                datetime(2025, 3, 31, 23, 59, 59, tzinfo=timezone.utc),
                "data/feat_2024_8_to_2025_3.parquet",
            ),
            (
                datetime(2025, 3, 1, tzinfo=timezone.utc),
                datetime(2025, 6, 30, 23, 59, 59, tzinfo=timezone.utc),
                "data/feat_2025_3_to_2025_6.parquet",
            ),
            (
                datetime(2025, 6, 1, tzinfo=timezone.utc),
                None,
                "data/feat_2025_6_to_now.parquet",
            ),
        ]

        for idx, (s_dt, e_dt, out_path) in enumerate(ranges, 1):
            print(f"\n===== å¼€å§‹ç¬¬ {idx} æ®µ =====")
            process_range(ex, conf, s_dt, e_dt, out_path)
        print("\nğŸ‰ å…¨éƒ¨æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        return

    # å•æ®µè¿è¡Œæ¨¡å¼ï¼ˆéœ€è¦æä¾› --from ä¸ --toï¼‰
    if not args.start_date or not args.end_date:
        print("âŒ è¯·æä¾› --from ä¸ --toï¼Œæˆ–ä½¿ç”¨ --run-all")
        return

    start_dt = parse_date_arg(args.start_date, is_end=False)
    end_dt = (
        None
        if args.end_date.lower() == "now"
        else parse_date_arg(args.end_date, is_end=True)
    )

    if end_dt is not None and start_dt > end_dt:
        raise ValueError("å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")

    process_range(ex, conf, start_dt, end_dt, args.output_path)


if __name__ == "__main__":
    main()
